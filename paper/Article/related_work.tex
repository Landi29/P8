\section{Related work}
\label{Related_work}
In "Page Ranking Algorithms: A Survey" N. Duhan et al.\cite{4809246} explains the concept of page rank and the evolution of the algorithm. There they explain strengths and weaknesses with each stage the algorithm has been through. The original PageRank algorithm is easy to implement and is the basis of PageRank. Weighted PageRank can be more precise and runs faster by looking at what input and output a page has.

"SimRank: A Measure of Structural-Context Similarity" written by G. Jeh and J. Widom\cite{10.1145/775047.775126} describes the SimRank algorithm and its uses on graphs. In SimRank two objects are similar if they are referenced by similar objects and an object is maximally similar to itself. This leads to similarity in different parts of a graph to be hard to find and uses vast amounts of memory $(O(n^2))$. SimRank is reliable in many cases of finding similar subgraphs.

"A Comprehensive Survey of Graph Embedding: Problems, Techniques, and Applications" by H. cai et al.\cite{8294302} summarizes and describes the terminology in graph embedding. They formulate what an input graph can be and what kind of embedding its mostly used for. The embedding methods are plentiful and are often made to conserve data in compact graphs. The embedding method results in different types of embedded graphs. Being node-, edge-, subgraph- or whole graph embedding.

"Type Extension Trees for feature construction and learning in relational domains" by M. Jaeger et al. \cite{JAEGER201330} defines a framework called Type-Extension-Trees (TETs) which are used to represent complex counts-of-counts features, which are complex combinatorial data structures in a relational domain. They present a learning algorithm which can be used to discover informative counts-of-counts features. These TET features can be made into prediction models either via the use of simple discriminant functions, which allows for binary classification or via the use of a metric on TET values, based on the Wasserstein-Kantorovich metric and allows for distance-based methods.

The article "Counts-of-counts similarity for prediction and search in relational data" by M. Jaeger et al.\cite{jaeger2019counts} gives a quick description of Type Extension Trees (TET) and Counts-of-Counts. The article uses the principles from "Type Extension Trees for feature construction and learning in relational domains" in forming the TETs and found substructures in databases. They show that it is possible to calculate similarity using logical evaluation and histograms or by using earth mover's distance (EMD).

"Knowledge Graph Embedding for Link Prediction and Triplet Classification" an article by E. Shijia et al. \cite{10.1007/978-981-10-3168-7_23} combats the problem of embedding knowledge graphs where graph embedding mostly has been used on social network graphs. Their solution is to learn semantic relations between entities in a form of edge embedding, where they later would be able to ask logical questions and get one or more relations.

In "Semi-supervised Graph Embedding for Multi-label Graph Node Classification" by K. Gao et al.\cite{10.1007/978-3-030-34223-4_35} they train a Graph convolution network to classify and embed subgraphs. They use a semi supervised technique because of the inconsistencies that can be found in multi-label graphs. This technique allows for unavailable relations to be represented, but since these relations are not part of the original graph, a "supervised learning only" strategy cannot be applied.
