\subsection{Result analysis}
The results of each test will in this section be compared to the baselise RMSE as seen in \autoref{fig:base_errors} and sytems RMSE.
\begin{figure}[H]
	\centering
	\begin{adjustbox}{width=0.5\textwidth}
		\input{Article/figures/base_10_fold_error.tex}
	\end{adjustbox}
	\caption{base error from 100k dating dataset }
	\label{fig:base_errors}
\end{figure}

In \autoref{fig:base_errors} is the baseline RMSE, we got this by using the average rating for the dataset as the prediction for all future rating.

\begin{figure}[H]
	\centering
	\begin{adjustbox}{width=0.5\textwidth}
		\input{Article/figures/brute_10_fold_error.tex}
	\end{adjustbox}
	\caption{bruteforce error from 100k dating dataset }
	\label{fig:brute_errors}
\end{figure}

\autoref{fig:brute_errors} show the RMSE for the 20 evaluations. the graph shows that with a relatively simple method recommendation can be done better than the baseline with an RMSE in most folds only having a difference of $0.01$ between validation and test sets.

\begin{figure}[H]
	\centering
	\begin{adjustbox}{width=0.5\textwidth}
		\input{Article/figures/N2V_10_fold_error.tex}
	\end{adjustbox}
	\caption{Node2vec error from 100k dating dataset }
	\label{fig:N2V_errors}
\end{figure}

The graph in \autoref{fig:N2V_errors} shows the most promising of our results with RMSE values being as low as 0.94. 


\begin{figure}[H]
	\centering
	\begin{adjustbox}{width=0.5\textwidth}
		\input{Article/figures/tet_10_fold_error.tex}
	\end{adjustbox}
	\caption{TET error from 100k dating dataset }
	\label{fig:tet_errors}
\end{figure}

