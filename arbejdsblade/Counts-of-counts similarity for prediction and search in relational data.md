## Counts-of-counts similarity for prediction and search in relational data

In the paper Jaeger et. Al presents a new metric that can be utilized to compare the similarity between graph entities which in turn can be utilized for searching and prediction on relational data.

#### Type Extension Trees (TET)

The metric is called counts-of-counts and works by using Type Extension Trees (TET's) to describe the counts-of-counts features, which describe the overall graph structure. An example of a TET can be seen below:

![TET](pictures/Counts-of-counts_Similarity/TET.png)

The definition of a TET can be seen below:

*A type extension tree (TET) is a rooted tree whose nodes are labeled with atoms, and whose edges can be labeled with variables.*

The idea behind it is that  A TET feature defines which relations to follow for assembling the relevant neighborhood, and what attributes of neighboring nodes to consider. This means that the nodes in a graph can fall into one of the features specified in the TET and can only connect to other features specified in the TET. An example of a graph using TET (a) seen above would be that we have an `author(A)` node those surrounding connected nodes would be `author_of(A,P)` node. Any nodes connected to the `author_of()` would then be of the type `cites(P',P)`.

![TET2](pictures\Counts-of-counts_Similarity\TET2.png)

If we want to find the value of a TET feature T(X) (where X is a set of free variables), for a k-tuple of graph entities $e$, denoted as $V(T(e))$, we do so via via the following example:

If we want to evaluate movie TET $T(M)$ for an entity we first check if the entity is a movie at all. If it is not then we return false as a value. If the entity is a movie then we return $(\{ f \}\{ f \}), (\{t\}\{ f \}), \{ f \}\{t\})$,or $(\{t\}\{t\})$ depending on whether that movies is a romance, a comedy, both or none of them. 

 If we instead want to evaluate our author TET then we first consider the sub-TET $T_1(A,P)$. This is evaluated for pairs of entities $(a, p)$, and returns false if `author_of(a, p)` is false. Otherwise $V(T_1(a,p))$ is $\{true:k\}$ where $k$ is the number of papers $p'$ that cite paper $p$. Evaluating the full TET for an author $a$ $V(T (a))$ gives us the multiset  $\{\{true : k_i\} : z_i\}  $ where $z_i$ is the number of papers $p$ by author $a$ with $k_i$ citations. All of this can be seen above in (c) where we show a tree that shows results of evaluating the TET. First middle part of the tree shows the result of evaluating on $V (T_1(a, p))$. Top part of the tree shows the result of $V(T (a))$. The root leaves show us the result for `cites(P',P)`.

#### Logistic evaluation

Once evaluation has occurred  we then need to find a way of using these values for prediction tasks and similarity measures. This can be via two approaches:

* Defining a rich class of evaluation functions $l^\beta$ that map TET values to real numbers and that are parameterized by an adjustable vector $\beta$;  
* Defining a metric on the nested multiset structure of real numbers that is generated by the recursive evaluation of $l^\beta $on a TET value $V (T (e))$.

With these two approaches we make the following definition for parametization of a TET:

*Let $T (X)$ be a TET. A weight assignment $β$ for T assigns a nonnegative*
*real number to all non-leaf nodes and all edges of $T$ . A weight assignment can be*
*written as $(β_0^r , β_1^r , . . . , β_m^r , β_1, . . . , β_m)$, where $β_0^r$ is the weight assigned to the root, $β_i^r$ is the weight assigned to the edge from the root to its i'th child, and $β_i$ is the weight assignment to the i'th sub-tree.*

Given a weight assignment for TET, we define a function on TET values $\gamma$  via a
recursive definition over the nested multiset structure of $\gamma$:

*For a TET $T$ with weight assignment $β$ the logistic evaluation function $l^β$ is defined as follows. Let $γ = V (T (e))$ be a value.*

*Base case*

- *If $\gamma = false$ then we define $l^\beta(\gamma):=0$* 
- *If $\gamma = true$ then we define $l^\beta(\gamma):=1$* 

*Recursion*

* If $γ = (μ_1, . . . , μ_m)$, with multisets $μ_i$ of values of sub-trees $T_i$, define:

* $$
  l^\beta(\gamma):=\sigma(\beta_0^r+\sum_{i=1}^m\beta^r_i * \sum_{\gamma'\in\mu_i}l^{\beta_i}(\gamma'))
  $$

  where $σ$ is the sigmoid function $σ (x) = 1/(1 + e^{-x})$.  

If we take an example of how the logistic evaluation function works on the author TET which was used earlier and where $\beta = (-14.7, 5.8)$ then if we look at (C) in the picture above then the bottom true values are evaluated to 1. At the middle level we evaluate the first value $\{t : 3\}$ as such: 
$$
l^{(−14.7,5.8)}(\{t : 3\}) = σ (−14.7 + 5.8 · (1 + 1 + 1)) = 0.937
$$
$\{t : 2\}$ would be evaluated as such:
$$
l^{(−14.7,5.8)}(\{t : 2\}) = σ (−14.7 + 5.8 · (1 + 1)) = 0.0431
$$
and lastly $\{t : 2\}$ as such:
$$
l^{(−14.7,5.8)}(\{t : 1\}) = σ (−14.7 + 5.8 · 1) = 0.0001
$$
For the top-level in (c) we evaluate as such
$$
l^{(−14.7,5.8,(−14.7,5.8))}(γ ) = σ (−14.7 + 5.8 · (0.93 + 0.0001 + 0.04 + 0.93 + 0.04))
= 0.03
$$
The final result of the logistic evaluation function $l^\beta(\gamma)$  is the root of the tree which is $0.03$. An example of the logistic evaluation tree an be seen in (d1) in the figure above. An alternative with other $\beta$ values are also used there.

#### Histogram approximation

Once the logistic evaluation tree has been computed we need to use to find distances between graph entities. An issue with logistic evaluation trees is that they can become quite large and complex which makes them unsuitable for quick distance measuring. Instead we want convert our logistic evaluation tree over to a node histogram tree from which we can run a similarity metric on.
